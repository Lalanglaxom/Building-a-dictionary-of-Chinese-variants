import sqlite3
import time
from urllib.parse import urljoin
from bs4 import BeautifulSoup
from selenium import webdriver
from selenium.webdriver.chrome.options import Options

# ── Selenium setup ───────────────────────────────
options = Options()
options.add_argument("--headless=new")    # run quietly in background
options.add_argument("--disable-gpu")
options.add_argument("--no-sandbox")
driver = webdriver.Chrome(options=options)

# ── SQLite setup ─────────────────────────────────
conn = sqlite3.connect("dictionary.db")
cur = conn.cursor()

cur.execute("""
CREATE TABLE IF NOT EXISTS variant_links (
    main_code TEXT,
    main_char TEXT,
    variant_char TEXT,
    href TEXT,
    data_ucs TEXT,
    data_sn TEXT,
    data_tp TEXT
)
""")

# ── Get list of entries from summary table ───────
cur.execute("SELECT code, char, detail_url FROM summary")
entries = cur.fetchall()

# ── Crawl each page ───────────────────────────────
for i, (main_code, main_char, url) in enumerate(entries, 1):
    print(f"[{i}/{len(entries)}] Fetching {main_char} → {url}")

    try:
        driver.get(url)
        # wait briefly for JS to load
        time.sleep(2)
        html = driver.page_source
    except Exception as e:
        print("❌ Error fetching:", e)
        continue

    soup = BeautifulSoup(html, "html.parser")

    # locate the <section id="vari">
    vari_section = soup.find("section", id="vari")
    if not vari_section:
        print(f"⚠️ No variant section for {main_char}")
        continue

    details_block = vari_section.find("details")
    if not details_block:
        print(f"⚠️ Details block missing for {main_char}")
        continue

    variant_links = details_block.find_all("a", href=True)
    if not variant_links:
        print(f"⚠️ No variant links found for {main_char}")
        continue

    for a in variant_links:
        href = urljoin("https://dict.variants.moe.edu.tw/", str(a.get("href", "")))
        data_ucs = str(a.get("data-ucs") or "")
        data_sn = str(a.get("data-sn") or "")
        data_tp = str(a.get("data-tp") or "")

        # visible character or alt text from <img>
        variant_char = a.get_text(strip=True)
        if not variant_char:
            img = a.find("img")
            if img and img.get("alt"):
                variant_char = img["alt"]

        cur.execute("""
            INSERT INTO variant_links (main_code, main_char, variant_char, href, data_ucs, data_sn, data_tp)
            VALUES (?, ?, ?, ?, ?, ?, ?)
        """, (main_code, main_char, variant_char, href, data_ucs, data_sn, data_tp))

    conn.commit()
    print(f"✅ Saved {len(variant_links)} variants for {main_char}")
    time.sleep(1)  # be polite to the server

driver.quit()
conn.close()
print("✅ Finished crawling all variant sections.")